import streamlit as st
import pandas as pd
import io
import math
from datetime import datetime

### åˆæœŸå‡¦ç† ###
# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ã¾ã¨ã‚ãƒ–ãƒ­ã‚°",
    page_icon="ğŸ“°"
)

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒˆãƒ«
st.title("ã¾ã¨ã‚ãƒ–ãƒ­ã‚°")

# CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
@st.cache_data
def load_data():
    try:
        # GitHubä¸Šã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã®Raw URLã‚’æŒ‡å®š
        url = "https://raw.githubusercontent.com/frameghostman/githubactionstest/refs/heads/main/blog_data.csv"
        return pd.read_csv(url)
    except Exception as e:
        st.error(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
        data = """date,url,title,source
2025-03-05,https://hamusoku.com/archives/10858699.html,ã‚¹ã‚¿ãƒã®ã‚­ãƒ©ã‚­ãƒ©å¥³æ€§åº—å“¡ã•ã‚“ã€€ã‚ã¾ã‚Šã«ã‚‚å‹ã¡çµ„é™½ã‚­ãƒ£æ„ŸãŒå‡„ã„,ãƒãƒ ã‚¹ã‚¿ãƒ¼é€Ÿå ±
2025-03-05,https://hamusoku.com/archives/10857168.html,æ±äº¬ã«æ¥ãŸã‚“ã‚„ãŒè‡­ãã¦è‰,ãƒãƒ ã‚¹ã‚¿ãƒ¼é€Ÿå ±
2025-03-05,https://hamusoku.com/archives/10858443.html,ã‚¢ãƒ¡ãƒªã‚«ã®ã‚«ãƒ¼ãƒ‰ã‚·ãƒ§ãƒƒãƒ—ã€€æ—¥æœ¬ã¨åŒã˜ãè‡­ã„ã“ã¨ãŒåˆ¤æ˜,ãƒãƒ ã‚¹ã‚¿ãƒ¼é€Ÿå ±
2025-03-05,https://hamusoku.com/archives/10858392.html,ãƒ¯ã‚¤ã€ç¦äº•çœŒç«‹å¤§å­¦æç«œå­¦éƒ¨ã«åˆæ ¼,ãƒãƒ ã‚¹ã‚¿ãƒ¼é€Ÿå ±"""
        return pd.read_csv(io.StringIO(data))

# ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†
df = load_data()
df['date'] = pd.to_datetime(df['date'])


### ã‚µã‚¤ãƒ‰ãƒãƒ¼ ###
# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’æä¾›
st.sidebar.header("ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚ªãƒ—ã‚·ãƒ§ãƒ³")

# æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
st.sidebar.subheader("æ—¥ä»˜ã§çµã‚Šè¾¼ã¿")
min_date = df['date'].min().date()
max_date = df['date'].max().date()
selected_date_range = st.sidebar.date_input(
    "æ—¥ä»˜ç¯„å›²ã‚’é¸æŠ",
    [min_date, max_date],
    min_value=min_date,
    max_value=max_date
)

# ã‚½ãƒ¼ã‚¹ï¼ˆã‚µã‚¤ãƒˆï¼‰ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
sources = df['source'].unique()
selected_sources = st.sidebar.multiselect("è¡¨ç¤ºã™ã‚‹ã‚½ãƒ¼ã‚¹ã‚’é¸æŠ", options=sources, default=list(sources))

# ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢
st.sidebar.subheader("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢")
search_term = st.sidebar.text_input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›")

# æ›´æ–°æƒ…å ±
st.sidebar.markdown("---")
st.sidebar.info(f"æœ€çµ‚æ›´æ–°: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}")


### ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ ###
## ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° ##
# æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
if len(selected_date_range) == 2:
    start_date, end_date = selected_date_range
    df = df[
        (df['date'].dt.date >= start_date) & 
        (df['date'].dt.date <= end_date)
    ]

# é¸æŠã•ã‚ŒãŸã‚½ãƒ¼ã‚¹ã«åŸºã¥ã„ã¦ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
if selected_sources:
    df = df[df['source'].isin(selected_sources)]
else:
    st.warning("å°‘ãªãã¨ã‚‚1ã¤ã®ã‚½ãƒ¼ã‚¹ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")

# ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢é©ç”¨
if search_term:
    df = df[
        df['title'].str.contains(search_term, case=False) | 
        df['source'].str.contains(search_term, case=False)
    ]

# ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ã®è¨­å®šï¼ˆ1ãƒšãƒ¼ã‚¸ã‚ãŸã‚Š50ä»¶ï¼‰
items_per_page = 50
total_items = len(df)
total_pages = math.ceil(total_items / items_per_page)

# ãƒšãƒ¼ã‚¸ç•ªå·ã®é¸æŠï¼ˆStreamlitã®number_inputã‚’åˆ©ç”¨ï¼‰
page = st.number_input("ãƒšãƒ¼ã‚¸ç•ªå·ã‚’é¸æŠ", min_value=1, max_value=total_pages, step=1, value=1)

start_index = (page - 1) * items_per_page
end_index = start_index + items_per_page
df_page = df.iloc[start_index:end_index]

# æœ€æ–°ã®è¨˜äº‹ã‚’ä¸Šã«è¡¨ç¤ºã™ã‚‹ãŸã‚ã«æ—¥ä»˜ã§ã‚½ãƒ¼ãƒˆ
df = df.sort_values(by='date', ascending=False)

# å„è¨˜äº‹ã®æƒ…å ±ã‚’è¡¨ç¤º
for index, row in df_page.iterrows():
    # ã‚¿ã‚¤ãƒˆãƒ«ã‚’ãƒªãƒ³ã‚¯ä»˜ãã§è¡¨ç¤ºï¼ˆã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨å…ƒè¨˜äº‹ã¸é£›ã³ã¾ã™ï¼‰
    st.markdown(f"##### [{row['title']}]({row['url']})")
    # æ—¥ä»˜ã¨ã‚½ãƒ¼ã‚¹æƒ…å ±ã®ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³è¡¨ç¤º
    st.caption(f"{row['date'].strftime('%Y-%m-%d')} | {row['source']}")
    st.write("---")
